{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1040b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "class BytePairEncoder:\n",
    "    def __init__(self):\n",
    "        self.merges = None\n",
    "        self.characters = None\n",
    "        self.tokens = None\n",
    "        self.vocab = None\n",
    "\n",
    "    def format_word(self, text, space_token='_'):\n",
    "        return ' '.join(list(text)) + ' ' + space_token\n",
    "\n",
    "    def initialize_vocab(self, text):\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        all_words = text.split()\n",
    "        vocab = {}\n",
    "        for word in all_words:\n",
    "            word = self.format_word(word)\n",
    "            vocab[word] = vocab.get(word, 0) + 1\n",
    "        tokens = collections.Counter(text)\n",
    "        return vocab, tokens\n",
    "\n",
    "    def get_bigram_counts(self, vocab):\n",
    "        pairs = {}\n",
    "        for word, count in vocab.items():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols)-1):\n",
    "                pair = (symbols[i], symbols[i+1])\n",
    "                pairs[pair] = pairs.get(pair, 0) + count\n",
    "        return pairs\n",
    "\n",
    "    def merge_vocab(self, pair, vocab_in):\n",
    "        vocab_out = {}\n",
    "        bigram = re.escape(' '.join(pair))\n",
    "        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "        bytepair = ''.join(pair)\n",
    "        for word in vocab_in:\n",
    "            w_out = p.sub(bytepair, word)\n",
    "            vocab_out[w_out] = vocab_in[word]\n",
    "        return vocab_out, (bigram, bytepair)\n",
    "\n",
    "    def find_merges(self, vocab, tokens, num_merges):\n",
    "        merges = []\n",
    "        for i in range(num_merges):\n",
    "            pairs = self.get_bigram_counts(vocab)\n",
    "            best_pair = max(pairs, key=pairs.get)\n",
    "            best_count = pairs[best_pair]\n",
    "            vocab, (bigram, bytepair) = self.merge_vocab(best_pair, vocab)\n",
    "            merges.append((r'(?<!\\S)' + bigram + r'(?!\\S)', bytepair))\n",
    "            tokens[bytepair] = best_count\n",
    "        return vocab, tokens, merges\n",
    "\n",
    "    def fit(self, text, num_merges):\n",
    "        vocab, tokens = self.initialize_vocab(text)\n",
    "        self.characters = set(tokens.keys())\n",
    "        self.vocab, self.tokens, self.merges = self.find_merges(vocab, tokens, num_merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e270a9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m y w o r l d _'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"myworld\"\n",
    "bpe = BytePairEncoder()\n",
    "\n",
    "vocab = {}\n",
    "bpe.format_word(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练BPE模型\n",
    "spm.SentencePieceTrainer.train('--model_type=bpe --input=blog_test.txt --model_prefix=bpe --vocab_size=500 --normalization_rule_tsv=normalization_rule.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练完模型后，加载它就可以使用了！\n",
    "sp_bpe = spm.SentencePieceProcessor()\n",
    "sp_bpe.load('bpe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800737d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c26f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(36).reshape((2,3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f279175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9, 10, 11],\n",
       "          [12, 13, 14, 15, 16, 17]],\n",
       " \n",
       "         [[18, 19, 20, 21, 22, 23],\n",
       "          [24, 25, 26, 27, 28, 29],\n",
       "          [30, 31, 32, 33, 34, 35]]]),\n",
       " tensor([[[[ 0,  1],\n",
       "           [ 2,  3],\n",
       "           [ 4,  5]],\n",
       " \n",
       "          [[ 6,  7],\n",
       "           [ 8,  9],\n",
       "           [10, 11]],\n",
       " \n",
       "          [[12, 13],\n",
       "           [14, 15],\n",
       "           [16, 17]]],\n",
       " \n",
       " \n",
       "         [[[18, 19],\n",
       "           [20, 21],\n",
       "           [22, 23]],\n",
       " \n",
       "          [[24, 25],\n",
       "           [26, 27],\n",
       "           [28, 29]],\n",
       " \n",
       "          [[30, 31],\n",
       "           [32, 33],\n",
       "           [34, 35]]]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.reshape(2, 3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff700ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
